{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 5\n",
    "\n",
    "Vamos a usar el dataset Fashion Mnist.\n",
    "\n",
    "Los objetivos de esta actividad es predecir el objeto en la foto entrenado distinctas redes neuronales.\n",
    "\n",
    "El notebook contiene basico codigo que descarga los datos y entrena y valida un modelo simple. Tu tienes que modificarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchsummary\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from sh import gunzip\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.data import loadlocal_mnist\n",
    "\n",
    "class FashionMnistLoader:\n",
    "    \n",
    "    dir_name = \"data/fashion\"\n",
    "    url_train_imgs = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\"\n",
    "    url_train_labels = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\"\n",
    "    url_test_imgs = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\"\n",
    "    url_test_labels = \"http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_imgs_fn = None\n",
    "        self.train_labels_fn = None\n",
    "        self.test_imgs_fn = None\n",
    "        self.test_labels_fn = None\n",
    "        \n",
    "    def get_all_data(self):\n",
    "        self.train_imgs_fn = self.get_data(self.url_train_imgs)\n",
    "        self.train_labels_fn = self.get_data(self.url_train_labels)\n",
    "        self.test_imgs_fn = self.get_data(self.url_test_imgs)\n",
    "        self.test_labels_fn = self.get_data(self.url_test_labels)\n",
    "        return self\n",
    "    \n",
    "    def load_train(self):\n",
    "        X, y = loadlocal_mnist(\n",
    "            images_path=self.train_imgs_fn, \n",
    "            labels_path=self.train_labels_fn)\n",
    "        return X, y\n",
    "    \n",
    "    def load_test(self):\n",
    "        X, y = loadlocal_mnist(\n",
    "            images_path=self.test_imgs_fn, \n",
    "            labels_path=self.test_labels_fn)\n",
    "        return X, y\n",
    "    \n",
    "    def _split(self, X, y, test_size):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=666)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "            \n",
    "    def train_split(self, test_size):\n",
    "        X, y = self.load_train()\n",
    "        X_train, X_test, y_train, y_test = self._split(X, y, test_size)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def standard_split(self):\n",
    "        X_train, y_train = self.load_train()\n",
    "        X_test, y_test = self.load_test()\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def get_data(self, url):\n",
    "        gz_file_name = url.split(\"/\")[-1]\n",
    "        gz_file_path = os.path.join(self.dir_name, gz_file_name)  \n",
    "        file_name = gz_file_name.split(\".\")[0]\n",
    "        file_path = os.path.join(self.dir_name, file_name)\n",
    "        os.makedirs(self.dir_name, exist_ok=True)\n",
    "        if not os.path.exists(file_path):\n",
    "            urllib.request.urlretrieve(url, gz_file_path) \n",
    "            gunzip(gz_file_path)  \n",
    "        return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784), 60000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = FashionMnistLoader().get_all_data()\n",
    "\n",
    "X_train_dev, X_test, y_train_dev, y_test = data_loader.standard_split()\n",
    "X_train_dev.shape, X_test.shape, len(y_train_dev), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), 50000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_dev, y_train, y_dev = data_loader.train_split(1/6)\n",
    "X_train.shape, X_dev.shape, len(y_train), len(y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch = torch.from_numpy(X_train).float()\n",
    "X_dev_torch = torch.from_numpy(X_dev).float()\n",
    "y_train_torch = torch.tensor(y_train.astype(np.int64))\n",
    "y_dev_torch = torch.tensor(y_dev.astype(np.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 10]           7,850\n",
      "================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_dim = 28 * 28\n",
    "\n",
    "class LinearNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_dim, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "simple_model = LinearNN()\n",
    "torchsummary.summary(simple_model, input_size=((1, input_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es equivalente a lo siguente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                [-1, 1, 10]           7,850\n",
      "================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 0.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "simple_model2 = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        ('fc', nn.Linear(in_features=input_dim, out_features=10, bias=True))\n",
    "    ]))\n",
    "torchsummary.summary(simple_model2, input_size=((1, input_dim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "n_epoch = 1000\n",
    "\n",
    "def train(model, n_epoch=n_epoch):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for i in range(n_epoch):\n",
    "        # 0. Anular los gradientes.\n",
    "        optimizer.zero_grad()\n",
    "        # 1. Generar la salida\n",
    "        output = model(X_train_torch)\n",
    "        # 2. Calcular función de pérdida\n",
    "        loss = criterion(output, y_train_torch)\n",
    "        # 3. Backward propagation\n",
    "        loss.backward()\n",
    "        # 4. Cambiar los pesos\n",
    "        optimizer.step()\n",
    "    y_train_score = model(X_train_torch).detach().numpy()\n",
    "    y_train_hat = np.argmax(y_train_score, axis=1)\n",
    "    print(accuracy_score(y_train, y_train_hat))\n",
    "    y_dev_score = model(X_dev_torch).detach().numpy()\n",
    "    y_dev_hat = np.argmax(y_dev_score, axis=1)\n",
    "    print(f\"Accuracy: train {accuracy_score(y_train, y_train_hat)}, dev {accuracy_score(y_dev, y_dev_hat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58218\n",
      "Accuracy: train 0.58218, dev 0.5831\n"
     ]
    }
   ],
   "source": [
    "train(simple_model, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
