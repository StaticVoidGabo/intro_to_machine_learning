{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a aplicar regularización $l_2$  y regularization $l_1$ usando el siguiente ejemplo de una competición de  <kaggle.com> llamado __House Prices: Advanced Regression Techniques__, ver <https://www.kaggle.com/c/house-prices-advanced-regression-techniques>. \n",
    "\n",
    "Por favor baja el dataset `train.cvs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n",
       "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu',\n",
       "       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars',\n",
       "       'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "       'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition',\n",
       "       'SalePrice'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/house-prices-advanced-regression-techniques/train.csv\"\n",
    "houses = pd.read_csv(path)\n",
    "houses.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos para evitar complejidad las columnas numericas din elementos NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = houses.select_dtypes(include=[np.number]).columns\n",
    "all_non_numeric_columns = houses.select_dtypes(exclude=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy = houses[numeric_columns]\n",
    "target_col = \"SalePrice\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrando las columnas con Nas values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 259\n",
      "MasVnrArea 8\n",
      "GarageYrBlt 81\n"
     ]
    }
   ],
   "source": [
    "cols_with_na = []\n",
    "for col in Xy.columns.values:\n",
    "    nas = sum(Xy[col].isna())\n",
    "    if nas > 0:\n",
    "        cols_with_na.append(col)\n",
    "        print(col, sum(Xy[col].isna()))\n",
    "        \n",
    "Xy = Xy.drop(cols_with_na, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos separación de datos de entrenamiento, test y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Xy.drop(target_col, axis=1)\n",
    "y = Xy[target_col]\n",
    "\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, random_state=666, test_size=0.2)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, random_state=667, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 1: Simple regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34461.69716294582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_dev_hat = reg.predict(X_dev)\n",
    "print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método 2: Regresiónn (l2-regularización)\n",
    "\n",
    "Dado el modeo lineal: \n",
    "\n",
    "\n",
    "$$\\hat{y} = a_1x_1 + \\ldots + a_nx_n + b$$\n",
    "\n",
    "\n",
    "\n",
    "Para regularización $l_2$, la función objetivo es :\n",
    "\n",
    "$$l(\\hat{Y}) = \\frac{1}{N}\\sum_i^N \\left(y_i - \\hat{y}_i\\right)^2 + \\alpha \\sum(a_1^2 + \\ldots + a_n^2)$$\n",
    "\n",
    "Este es llamado Ridge.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34461.678180096664 0.0009765625\n",
      "34461.65919907327 0.001953125\n",
      "34461.62124246699 0.00390625\n",
      "34461.54535101685 0.0078125\n",
      "34461.39365516826 0.015625\n",
      "34461.09061110556 0.03125\n",
      "34460.485909638504 0.0625\n",
      "34459.28202148575 0.125\n",
      "34456.89605317127 0.25\n",
      "34452.20938684532 0.5\n",
      "34443.16215816408 1\n",
      "34426.262776393334 2\n",
      "34396.51044932244 4\n",
      "34348.951020385815 8\n",
      "34282.42188338061 16\n",
      "34202.48205212977 32\n",
      "34125.16701254985 64\n",
      "34099.00768051498 128\n",
      "34245.40793648863 256\n",
      "34744.590236435695 512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "for i in range(-10, 10):\n",
    "    alpha = 2**i\n",
    "    ridge_reg = Ridge(alpha=alpha)\n",
    "    ridge_reg.fit(X_train, y_train)\n",
    "    y_dev_hat = ridge_reg.predict(X_dev)\n",
    "    print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)), alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es entonces el mejor modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression (l1 regularización)\n",
    "\n",
    "En este caso la función objetivo es:\n",
    "\n",
    "$$l(\\hat{Y}) = \\frac{1}{N}\\sum_i^N \\left(y_i - \\hat{y}_i\\right)^2 + \\alpha \\sum(|a_1| + \\ldots + |a_n|)$$\n",
    "\n",
    "Este es llamado Lasso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34461.69542173473 0.0009765625\n",
      "34461.69368052823 0.001953125\n",
      "34461.6901981263 0.00390625\n",
      "34461.683233412696 0.0078125\n",
      "34461.66930413723 0.015625\n",
      "34461.64144640941 0.03125\n",
      "34461.58573441035 0.0625\n",
      "34461.47432458774 0.125\n",
      "34461.2515619947 0.25\n",
      "34460.80626696905 0.5\n",
      "34459.91658585277 1\n",
      "34458.14084437147 2\n",
      "34454.60385885485 4\n",
      "34447.587976514675 8\n",
      "34433.78811793976 16\n",
      "34407.119962130426 32\n",
      "34357.519619665545 64\n",
      "34288.09525971574 128\n",
      "34229.02126168853 256\n",
      "34270.67818181146 512\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for i in range(-10, 10):\n",
    "    alpha = 2**i\n",
    "    lasso_reg = Lasso(alpha=alpha)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "    y_dev_hat = lasso_reg.predict(X_dev)\n",
    "    print(np.sqrt(mean_squared_error(y_dev, y_dev_hat)), alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es el mejor modelo?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación de los coeficientes en Lasso\n",
    "\n",
    "En Lasso hay un interesante efecto en anular bastantes coeficientes\n",
    "cuando aplicamos regularización. Veamos un ejemplo para $\\alpha = 100000$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.17677896e+00, -5.19281675e+01,  1.81804546e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  4.60597162e+02,  3.74462039e+02,  1.25190335e+01,\n",
       "        0.00000000e+00, -0.00000000e+00,  2.42657167e+01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  6.60160074e+01,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        6.00591708e+01,  3.89130770e+01, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  6.20233278e+01, -1.61332470e+02, -5.81768963e+00,\n",
       "        0.00000000e+00, -0.00000000e+00])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha=100000)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compara lo con regularización l2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.74360780e+00, -1.16036290e+02,  1.49606822e-01,  1.54492603e+02,\n",
       "        3.53637430e+01,  5.12887253e+02,  4.73797562e+02,  1.56538396e+01,\n",
       "        3.83463135e+00,  1.73549128e+00,  2.12239622e+01,  1.09050761e+01,\n",
       "        1.37610861e+01,  2.87665725e+01,  5.34327347e+01,  1.11132958e+01,\n",
       "       -2.12506534e+00,  8.81515714e+00,  1.44562256e-02, -3.37008992e+01,\n",
       "       -1.24206558e+01,  1.52790155e+01,  3.37324777e+01,  2.43274700e+01,\n",
       "        5.59984263e+01,  4.30133223e+01, -1.16274809e+01,  1.95784426e+01,\n",
       "        6.77256124e+01,  9.63614776e+01, -2.17259354e+02, -6.30007045e+00,\n",
       "        3.33652332e+01, -1.91128798e+01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg = Ridge(alpha=100000)\n",
    "ridge_reg.fit(X_train, y_train)\n",
    "ridge_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic Net: ambas regularizaciones al mismo timepo\n",
    "\n",
    "Hay un tercer tipo de regularización que trabaja muy bien que es la combinación de $l_2$ y $l_1$:\n",
    "\n",
    "\n",
    "$$l(\\hat{Y}) = \\frac{1}{N}\\sum_i^N \\left(y_i - \\hat{y}_i\\right)^2 + \n",
    "\\alpha_1 \\sum(|a_1| + \\ldots + |a_n|)+\n",
    "\\alpha_1 \\sum((a_1)^2 + \\ldots + (a_n)^2)\n",
    "$$\n",
    "\n",
    "El modelo lineal con esta función objetivo es a menudo llamdadoElastic Net. Esta tienes dos parámetros  `alpha` y `l1_ratio` y la relación entre ellos es la siguiente:\n",
    "\n",
    "$$\\alpha_1 = \\texttt{alpha}\\cdot\\texttt{l1_ratio}$$\n",
    "\n",
    "$$\\alpha_2 = \\texttt{alpha}\\cdot(\\texttt{1 - l1_ratio})$$\n",
    "\n",
    "Veamos en el ejemplo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "alpha_ratio_score = []\n",
    "\n",
    "for i in range(-10, 10):\n",
    "    for j in range(20):\n",
    "        alpha = 2**i\n",
    "        l1_ratio = 0.6**j\n",
    "        en_reg = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "        en_reg.fit(X_train, y_train)\n",
    "        y_dev_hat = en_reg.predict(X_dev)\n",
    "        alpha_ratio_score.append([alpha, l1_ratio, np.sqrt(mean_squared_error(y_dev, y_dev_hat)), alpha, l1_ratio])\n",
    "        \n",
    "scores = pd.DataFrame({\n",
    "    \"alpha\": [ars[0] for ars in alpha_ratio_score],\n",
    "    \"ratio\": [ars[1] for ars in alpha_ratio_score],\n",
    "    \"score\": [ars[2] for ars in alpha_ratio_score]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>ratio</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>34095.612059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>34095.612107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>34095.612188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>34095.612327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>34095.612565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha     ratio         score\n",
       "159  0.125  0.000061  34095.612059\n",
       "158  0.125  0.000102  34095.612107\n",
       "157  0.125  0.000169  34095.612188\n",
       "156  0.125  0.000282  34095.612327\n",
       "155  0.125  0.000470  34095.612565"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values('score').head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
